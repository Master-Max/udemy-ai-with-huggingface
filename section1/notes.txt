Transformers

Encoder (left block)
    converts words into tokens (vectors)
    adds info
    gets data from the user
    add attention - each word pays attention to the other words in the sentence

Decoder (right block)
    generates output tokens
    only looks at previous words

________

Tokens add data in the Encoder phase
[CLS] - start of sentence
[SEP] = end of sentence

________

Uses google colab

> from transformers import AutoTokenizer

CLS and SEP change depending on model being used

________

Some models need only encoder or only Decoder

Encoder Only:
    - Text Classifiication (identifying spam or not spam)
Named Entity Recognition (NER):
    - identifying John as a person and London as a location
Sentiment Analysis:
    - Is a review of a movie positive or negative
Text Similarity
    - Compare 2 sentences to see how similar they AutoTokenizer


Example Full Models (That I can probably find on Hugging Face)
    - ALBERT
    - BERT
    - DistilBERT
    - ELECTRA
    - RoBERTa

________

Decoder Only:

(does actually need an encoder to make a token) ???

Text Generation
Text Summarization
Speech Recognition

Full Models
    - CTRL
    - GPT, GPT 1,2,3,4,4o
    - Claude, Gemini


________

Multi Level Attention and Feed Forward

________

How Transformers work

Encoder - text to representation
Decoder - representation to output

Tokenization - Encoder takes text and tokenizes it into layers
    - embeded into vectors using embedding layers

Embedding   EMBEDDING!
    - way to represent words, sentences or other types of data as Numberical Vectors
    - Vectors capture the meaning, relationships and sturcture of the data
    - Very important
    - preserves meaning with multi dimentional vectors
    - also uses positional context ( I think position in sentence is a layer that the token will have a vector on )

Multi-Head Attention (or Self Attention)
    - Each token embedding is projected into three vectors:
        * Query (Q) what is token looking for?
        * Key (K) features of token that other tokens can reference
        * Value (V) imformation that the token contributes

    The more meaningful the embeddings, the better the attention mechanism

Multi-Head Attention works in parallel
    Each head focuses on different relationships in the sentence
    one might forus on grammer another might focus on the meaning

FFNN - Feed Forward Neural Network
    Data is normalized and sent to FFNN, each token is independently processed
    Adds abstractions?????

Decoder - takes input from encoder and perform action of predicting the next work in the sequence

All of this is based on the Attention is All You Need paper






